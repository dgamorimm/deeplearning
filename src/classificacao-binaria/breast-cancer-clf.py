from rich import print
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import confusion_matrix, accuracy_score
import pandas as pd
import os

##### AnotaÃ§Ãµes ######
# O modelo Ã© Sequential justamente poque ele tem a camada de entrada, camda oculta e de saÃ­da
# Vamos utilizar camadas Dense(Densas) em uma rede neural. Siginifica que cada um dos neuronios Ã© ligado na camada subsequente

PATH_DATA = os.path.join(os.path.dirname(__file__),'data')

def save_txt(predictions):
    # Criar data frame
    df = pd.DataFrame(predictions)
    
    # Formatando os valores sem notaÃ§Ã£o cientÃ­fica
    df_formatted = df.apply(lambda x: '{:.0f}'.format(x[0]), axis=1)
    
    # Salvando o DataFrame formatado em um arquivo de texto
    df_formatted.to_csv(PATH_DATA + '\\classe_prevista.txt', index=False, header=False)

# Lendo os dados dos previsores e das classes
previsores = pd.read_csv(PATH_DATA + '\\entradas_breast.csv')
classe = pd.read_csv(PATH_DATA + '\\saidas_breast.csv')
print("ğŸ File: src/breast-cancer-clf.py | Line: 9 | undefined ~ previsores",previsores.shape)
print("ğŸ File: src/breast-cancer-clf.py | Line: 11 | undefined ~ classe",classe.shape)

# Separando dados de teste e treino
previsores_treinamento,\
previsores_teste,\
classe_treinamento,\
classe_teste = train_test_split(previsores, classe, test_size=0.25)

# salvando a classe teste para avaliar posteriormente com o dado previsto
classe_teste.to_csv(PATH_DATA + '\\classe_teste.csv', index=True, header=False)

print('\n')
print("ğŸ File: src/breast-cancer-clf.py | Line: 15 | undefined ~ previsores_treinamento",previsores_treinamento.shape)
print("ğŸ File: src/breast-cancer-clf.py | Line: 16 | undefined ~ previsores_teste",previsores_teste.shape)
print("ğŸ File: src/breast-cancer-clf.py | Line: 17 | undefined ~ classe_treinamento",classe_treinamento.shape)
print("ğŸ File: src/breast-cancer-clf.py | Line: 18 | undefined ~ classe_teste",classe_teste.shape)

# Criando a rede neural
classificador = Sequential()

## Criando a primeira camada oculta
## no keras nÃ£o definimos a quantidade da camada de entrada, ja iniciamos a partir da camada oculta
## para sabermos a quantidade de neuronios na camada oculta podemos fazer a seguinte formula
## units = quantidadeEntrada + quantidadeSaida / 2
## quantidadeEntrada = 30, pois no nossa base de dados previsores, possui 30 colunas
## quantidadeSaida = Como queremos saber se maligno ou bnigno, existe apenas uma unica saida, entÃ£o numero 1
## calculo ---> units = (30 + 1) / 2 =  15.5 arredondar para cima 16
## usando a funÃ§Ã£o de ativaÃ§Ã£o relu por recomendaÃ§Ã£o de boas prÃ¡ticas comerciais, ela tende a dar mais certo do que a sigmoid, hiperbolice e etc.
## kernel_initializar = Ã© como vocÃª vai inicializar o balancemaento dos pesos, por padrÃ£o , utilizamos o random uniform
## input_dim  = define quantas entradas vocÃª tem no seu modelo. Como vimos anteriormente temos 30. Define 30 neuronios na entrada

### Camada Oculta
classificador.add(
    Dense(
        units=16,
        activation='relu',
        kernel_initializer= 'random_uniform',
        input_dim = 30
    )
)


## como sÃ³ temos uma possivel saida , Benigno ou Maligno, entÃ£o utilizaremos units = 1
## utilizaremos a funÃ§Ã£o de ativaÃ§Ã£o sigmoid, pois ela retorna valores entre 0 e 1, que Ã© o nosso caso, poistemos uma resposta binÃ¡ria

### Camada de Saida
classificador.add(
    Dense(
        units=1,
        activation='sigmoid'
    )
)


## optimizer: qual pe a funÃ§Ã£o para fazer o ajuste dos pesos, entra na parte da descida do gradiente + descida do gradiente estocastico
## Ã© recomendado que comeÃ§amos a utlizar o optimizer 'adam', Ã© o que melhor se adpta na maioria dos casos
## loss: Ã© a nossa funÃ§Ã£o de perda, a mneira que vai fazer o tratamento ou o calculo do erro
## quanto menor o loss, melhor
## como temos um problema de classificaÃ§Ã£o binÃ¡rio, Ã© recomendado que utilize o 'binary_crossentropy'
## Ã© recomendado usar o crossentropy , pois ele usa o logaritmo, ele vai de certa forma vai utilizar a perda atravÃ©s de uma regressÃ£o logistica
## usamos a mÃ©trica de binary_accuracy, pois estamos com problema de classificaÃ§Ã£o binÃ¡ria

### Compilando nossa rede neural
classificador.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics= ['binary_accuracy']
    )

## fit: significa achar a correlaÃ§Ã£o entre os valores de treinamento
## batch_size : vai calcular o erro para 10 registros e depois ele vai atualizar os pesos
## epochs : quantas vezes eu quero fazer os ajustes dos pesos
### Treinando
classificador.fit(
    previsores_treinamento,
    classe_treinamento,
    batch_size=10,
    epochs=100
)

## Para prever, temos que testar, para isso devemos passar a base de teste
## estou salvando o as previsoes para analisar junto a classe_teste.csv
## seguindo a funÃ§Ã£o de ativaÃ§Ã£o se o valor previsto for > 0.5, entÃ£o Ã© True se nÃ£o Ã© False
### Realizando as previsÃµes
previsoes = classificador.predict(
    previsores_teste
)
previsoes = (previsoes > 0.5)
save_txt(previsoes)

## precisÃ£o: indica o percentual de acerto
## matriz de confusÃ£o :[[40  9][ 3 91]] , ou seja os que deram 0 eu acertei 40 e errei 9, o que deu 1 eu acertei 91 e errei 3.
## resultado: Ã© o valor da perda, com o a precisÃ£o
### Analisando a acurÃ¡cia
precisao = accuracy_score(classe_teste, previsoes)
print("ğŸ File: src/breast-cancer-clf.py | Line: 123 | undefined ~ precisao",precisao)
matriz = confusion_matrix(classe_teste, previsoes)
print("ğŸ File: src/breast-cancer-clf.py | Line: 125 | undefined ~ matriz",matriz)
resultado = classificador.evaluate(previsores_teste, classe_teste)
print("ğŸ File: src/breast-cancer-clf.py | Line: 127 | undefined ~ resultado",resultado)