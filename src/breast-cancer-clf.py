from rich import print
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense
import pandas as pd
import os

##### Anota√ß√µes ######
# O modelo √© Sequential justamente poque ele tem a camada de entrada, camda oculta e de sa√≠da
# Vamos utilizar camadas Dense(Densas) em uma rede neural. Siginifica que cada um dos neuronios √© ligado na camada subsequente

PATH_DATA = os.path.join(os.path.dirname(__file__),'data')

# Lendo os dados dos previsores e das classes
previsores = pd.read_csv(PATH_DATA + '\\entradas_breast.csv')
classe = pd.read_csv(PATH_DATA + '\\saidas_breast.csv')
print("üêç File: src/breast-cancer-clf.py | Line: 9 | undefined ~ previsores",previsores.shape)
print("üêç File: src/breast-cancer-clf.py | Line: 11 | undefined ~ classe",classe.shape)

# Separando dados de teste e treino
previsores_treinamento,\
previsores_teste,\
classe_treinamento,\
classe_teste = train_test_split(previsores, classe, test_size=0.25)

print('\n')
print("üêç File: src/breast-cancer-clf.py | Line: 15 | undefined ~ previsores_treinamento",previsores_treinamento.shape)
print("üêç File: src/breast-cancer-clf.py | Line: 16 | undefined ~ previsores_teste",previsores_teste.shape)
print("üêç File: src/breast-cancer-clf.py | Line: 17 | undefined ~ classe_treinamento",classe_treinamento.shape)
print("üêç File: src/breast-cancer-clf.py | Line: 18 | undefined ~ classe_teste",classe_teste.shape)

# Criando a rede neural
classificador = Sequential()

## Criando a primeira camada oculta
## no keras n√£o definimos a quantidade da camada de entrada, ja iniciamos a partir da camada oculta
## para sabermos a quantidade de neuronios na camada oculta podemos fazer a seguinte formula
## units = quantidadeEntrada + quantidadeSaida / 2
## quantidadeEntrada = 30, pois no nossa base de dados previsores, possui 30 colunas
## quantidadeSaida = Como queremos saber se maligno ou bnigno, existe apenas uma unica saida, ent√£o numero 1
## calculo ---> units = (30 + 1) / 2 =  15.5 arredondar para cima 16
## usando a fun√ß√£o de ativa√ß√£o relu por recomenda√ß√£o de boas pr√°ticas comerciais, ela tende a dar mais certo do que a sigmoid, hiperbolice e etc.
## kernel_initializar = √© como voc√™ vai inicializar o balancemaento dos pesos, por padr√£o , utilizamos o random uniform
## input_dim  = define quantas entradas voc√™ tem no seu modelo. Como vimos anteriormente temos 30. Define 30 neuronios na entrada

### Camada Oculta
classificador.add(
    Dense(
        units=16,
        activation='relu',
        kernel_initializer= 'random_uniform',
        input_dim = 30
    )
)


## como s√≥ temos uma possivel saida , Benigno ou Maligno, ent√£o utilizaremos units = 1
## utilizaremos a fun√ß√£o de ativa√ß√£o sigmoid, pois ela retorna valores entre 0 e 1, que √© o nosso caso, poistemos uma resposta bin√°ria

### Camada de Saida
classificador.add(
    Dense(
        units=1,
        activation='sigmoid'
    )
)


## optimizer: qual pe a fun√ß√£o para fazer o ajuste dos pesos, entra na parte da descida do gradiente + descida do gradiente estocastico
## √© recomendado que come√ßamos a utlizar o optimizer 'adam', √© o que melhor se adpta na maioria dos casos
## loss: √© a nossa fun√ß√£o de perda, a mneira que vai fazer o tratamento ou o calculo do erro
## quanto menor o loss, melhor
## como temos um problema de classifica√ß√£o bin√°rio, √© recomendado que utilize o 'binary_crossentropy'
## √© recomendado usar o crossentropy , pois ele usa o logaritmo, ele vai de certa forma vai utilizar a perda atrav√©s de uma regress√£o logistica
## usamos a m√©trica de binary_accuracy, pois estamos com problema de classifica√ß√£o bin√°ria

### Compilando nossa rede neural
classificador.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics= ['binary_accuracy']
    )

## fit: significa achar a correla√ß√£o entre os valores de treinamento
## batch_size : vai calcular o erro para 10 registros e depois ele vai atualizar os pesos
## epochs : quantas vezes eu quero fazer os ajustes dos pesos
### Treinando
classificador.fit(
    previsores_treinamento,
    classe_treinamento,
    batch_size=10,
    epochs=100
)