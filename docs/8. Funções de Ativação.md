# Step (função degrau)
- usado para conjunto de dados linerarmente separados
- conjunto de dados simples onde se obtem apenas dois valores (0 ou 1)
- muito pouco ou nunca utilizado

# Sigmoid (função sigmoide)
- formula: $y = \frac{1}{1 + e^{-x}}$
- conjunto de dados mais complexos se obtem valores próximos de (0 ou 1)
- resolve apenas problemas binários (0 ou 1) ou duas classes.
  - Exemplos:
    - Gatos ou Cachorros
    - Vai Pagar ou Não Vai Pagar
    - Vai comprar o produto ou não
- resolve os problemas não linearmente separaveis
  
# Hyperbolic tanget (função tangente hiperbólica)
- formula: $y = \frac{{e^x} - {e^{-x}}}{{e^x} + {e^{-x}}}$
- pode ser utilizada quando tem duas classe
- se tiver entradas negativas, elas serão mapeadas fortemente negativas. Valores próximos de zero també serão aproximados de zero
- usada para conjunto de dados mais complexos onde os valores não são linearmente separaveis
- os valores podm ir de próximos a -1 a 1

# ReLU (rectified linear units)
- formula: $y = max(0,x)$
- retorna valores 0 ou maiores do que zero
- função bastante simples, não existe um calculo matemático muito complexo
- não existe um valor máximo
- função mais usada atualmente, principalmente em redes neurais covolucionais e profundas que tem grandes numeros de camadas
- se você tiver muitos valores negativos, essa função não é muito bem recomendada

# Linear
- utilizado mais para regressão

# Softmax
- formula: $y = \frac{e(x)}{\sum\ {e(x)}}$
- função mais importante de redes neurais
- utilizado para retornar probabilidades quando você possui mais de duas classes
- Exemplo:
  - quero tentar prever a cor
    - pode ser verde, azul, roxo, vermelho e etc..
- usado para classificação com mais dados
- retorna probabilidades para cada uma das classes