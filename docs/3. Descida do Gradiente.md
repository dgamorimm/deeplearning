# Gradiente
- Encontrar a combinação de pesos que o erro é o menor possível
- Gradiente é calculado para saber quanto ajustar os pesos
- O ideal é chegar no minimo global
- Vai cair o declive da curva com as derivadas parciais

## Achando o gradiente
- Você passa o resultado do valor de ativação do sigmoide 
  - formula: $y = \frac{1}{1 + e^{-x}}$
- Depois que obtem o resultado você passa para a derivada de ativação
  - formula: $d = y * (1 - y)$
- É o valor da derivada que vai te dizer se você vai ter que aumentar ou diminuir os pesos para se adaptar melhor aos dados

## Calculo do parâmetro delta
- Seguindo o sequenciamento
  - Função Ativação
  - Derivada da função
  - Delta
  - Gradiente

### 1. Delta Saída
- pegando o exemplo do REG1 da rede multicamadas
- formula:
  - DeltaSaida = Erro * DerivadaSigmoide
- Tivemos os seguintes dados
  - Soma: -0.381
  - Ativação(y) : 0.406
  - Erro: 0 - 0.406 = -0.406
  - Derivada ativação: 0.406 * (1 - 0.406) = 0.241
  - Delta Saida: -0.406 * 0.241 = -0.098
- repete este mesmo processo para todos os registros

### 2. Delta Camada Escondida
- formula:
  - DeltaEscondida = DerivadaSigmoide * peso * DeltaSaída
- A Ativação do RG1 para cada camada oculta foi de 0,5 para cada neuronio, portanto a derivada sigmoide de todas é de 0,25 aplicando a formula.
- Calculo
  - NEU1: 0,25 * (-0.017) * (-0.098) = 0.000
  - NEU2: 0,25 * (-0.893) * (-0.098) = 0.022
  - NEU3: 0,25 * 0.148 * (-0.098) = -0.004
- repete para todos os outros registros